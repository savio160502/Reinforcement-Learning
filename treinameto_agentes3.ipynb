{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "vSQEycf6mOm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58f9b8f-d0a1-4fbf-f680-246143d1ddae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pylint gymnasium stable_baselines3"
      ],
      "metadata": {
        "id": "-WgFKeKngRXS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "import subprocess\n",
        "import shutil\n",
        "from transformers import pipeline\n",
        "import os\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import logging\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.logger import configure\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uUfy3Dc0vGvp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurando ambiente"
      ],
      "metadata": {
        "id": "dqxiB2uGvInC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar logging\n",
        "logging.basicConfig(filename='agentes_conversa.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "\n",
        "class DataAnalysisEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Ambiente personalizado para agentes cooperativos de análise de dados.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_path):\n",
        "        super(DataAnalysisEnv, self).__init__()\n",
        "\n",
        "        # Carrega o dataset Walmart\n",
        "        self.data = pd.read_csv(data_path)\n",
        "\n",
        "        # Definição dos espaços de ação para os dois agentes (combinados em um Dict)\n",
        "        self.action_space = spaces.MultiDiscrete([4, 5])  # Codificador tem 4 ações, Revisor tem 5 ações\n",
        "\n",
        "        # Definindo um espaço para as observações numéricas\n",
        "        self.max_codigo_length = 1000\n",
        "        self.max_relatorio_length = 1500\n",
        "\n",
        "        total_length = self.max_codigo_length + self.max_relatorio_length + 1  # Código, Relatório e o score\n",
        "\n",
        "        # Espaço de observação agora é um único Box contínuo\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0,\n",
        "            high=1,  # Normalizado para ficar entre 0 e 1\n",
        "            shape=(total_length,),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Inicialização das variáveis de estado\n",
        "        self.state = {\n",
        "            \"codigo\": np.zeros(self.max_codigo_length, dtype=np.int32),\n",
        "            \"relatorio\": np.zeros(self.max_relatorio_length, dtype=np.int32),\n",
        "            \"score_relatorio\": np.array([0.0], dtype=np.float32)\n",
        "        }\n",
        "\n",
        "        self.threshold_score = 135  # 90% de 150 pontos\n",
        "\n",
        "        self.temp_dir = tempfile.mkdtemp()\n",
        "        self.linter = 'pylint'\n",
        "\n",
        "        # Modelos LLM para Codificador e Revisor\n",
        "        self.codificador_llm = pipeline('text-generation', model='Salesforce/codegen-350M-mono', device=0 if torch.cuda.is_available() else -1)\n",
        "        self.revisor_llm = pipeline('text-generation', model='Salesforce/codegen-350M-mono', device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # Configura a semente para garantir repetibilidade (se aplicável)\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        # Redefine o estado\n",
        "        self.state = {\n",
        "            \"codigo\": np.zeros(self.max_codigo_length, dtype=np.int32),\n",
        "            \"relatorio\": np.zeros(self.max_relatorio_length, dtype=np.int32),\n",
        "            \"score_relatorio\": np.array([0.0], dtype=np.float32)\n",
        "        }\n",
        "\n",
        "        # Retorna a observação como um vetor contínuo\n",
        "        observation = np.concatenate([\n",
        "            self.state['codigo'] / 65535,  # Normalizando valores Unicode entre 0 e 1\n",
        "            self.state['relatorio'] / 65535,\n",
        "            self.state['score_relatorio'] / 150\n",
        "        ]).astype(np.float32)\n",
        "\n",
        "        return observation, {}\n",
        "\n",
        "    def step(self, actions):\n",
        "        done = False\n",
        "        info = {}\n",
        "\n",
        "        # Ações dos agentes\n",
        "        action_codificador = actions[0]\n",
        "        action_revisor = actions[1]\n",
        "\n",
        "        # Codificador gera código\n",
        "        codigo_gerado = self.execute_action_codificador(action_codificador)\n",
        "        self.state['codigo'][:len(codigo_gerado)] = [ord(c) for c in codigo_gerado]  # Usa ord() para valores Unicode\n",
        "\n",
        "        # Log e print da ação do codificador\n",
        "        logging.info(f\"Codificador ação: {action_codificador} -> Código gerado:\\n{codigo_gerado}\")\n",
        "        print(f\"Codificador ação: {action_codificador} -> Código gerado:\\n{codigo_gerado}\")\n",
        "\n",
        "        # Executa e avalia o código\n",
        "        exec_result, exec_error = self.avaliar_codigo(codigo_gerado)\n",
        "        linter_output = self.rodar_linter(codigo_gerado)\n",
        "\n",
        "        codigo_esta_correto = exec_error is None\n",
        "\n",
        "        # Revisor gera feedback\n",
        "        feedback = self.execute_action_revisor(action_revisor, exec_error, linter_output)\n",
        "        self.state['relatorio'][:len(feedback)] = [ord(c) for c in feedback]  # Usa ord() para valores Unicode\n",
        "\n",
        "        # Log e print da ação do revisor\n",
        "        logging.info(f\"Revisor ação: {action_revisor} -> Feedback gerado:\\n{feedback}\")\n",
        "        print(f\"Revisor ação: {action_revisor} -> Feedback gerado:\\n{feedback}\")\n",
        "\n",
        "        # Calcula a pontuação do relatório\n",
        "        self.state['score_relatorio'] = self.calcular_score_relatorio(feedback)\n",
        "        normalized_score = min(self.state['score_relatorio'][0] / 150, 1.0)\n",
        "        self.state['score_relatorio'][0] = normalized_score\n",
        "\n",
        "        # Calcular recompensa\n",
        "        reward_codificador = 1.0 if codigo_esta_correto else -1.0\n",
        "        reward_revisor = self.state['score_relatorio'][0] / 150\n",
        "        combined_reward = (reward_codificador + reward_revisor) / 2  # Média das recompensas\n",
        "\n",
        "        # Log e print das recompensas\n",
        "        logging.info(f\"Recompensa Codificador: {reward_codificador}, Recompensa Revisor: {reward_revisor}, Recompensa Combinada: {combined_reward}\")\n",
        "        print(f\"Recompensa Codificador: {reward_codificador}, Recompensa Revisor: {reward_revisor}, Recompensa Combinada: {combined_reward}\")\n",
        "\n",
        "        # Verificar se o episódio terminou\n",
        "        if self.state['score_relatorio'] >= self.threshold_score:\n",
        "            done = True\n",
        "\n",
        "        # Concatenar código, relatório e score em uma única observação\n",
        "        observation = np.concatenate([\n",
        "            self.state['codigo'] / 65535,  # Normalizando valores Unicode entre 0 e 1\n",
        "            self.state['relatorio'] / 65535,\n",
        "            self.state['score_relatorio'] / 150  # Normalizando o score entre 0 e 1\n",
        "        ]).astype(np.float32)\n",
        "\n",
        "        return observation, combined_reward, done, False, info  # Retornando o valor `False` para truncated\n",
        "\n",
        "    def execute_action_codificador(self, action):\n",
        "        actions_map = {\n",
        "            0: \"Processar os dados.\",\n",
        "            1: \"Analisar os dados.\",\n",
        "            2: \"Visualizar os resultados.\",\n",
        "            3: \"Interpretar a análise.\"\n",
        "        }\n",
        "\n",
        "        action_text = actions_map.get(action, \"\")\n",
        "        prompt = f\"Escreva uma função Python para {action_text} usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\"\n",
        "\n",
        "        # Gera o código, mas limita o número de tokens gerados\n",
        "        generated = self.codificador_llm(prompt, max_new_tokens=50, num_return_sequences=1)\n",
        "        codigo = generated[0]['generated_text']\n",
        "\n",
        "        # Truncar o código gerado para o tamanho máximo permitido\n",
        "        codigo = codigo[:1024]  # Truncando para 1024 caracteres\n",
        "\n",
        "        return codigo\n",
        "\n",
        "    def execute_action_revisor(self, action, exec_error, linter_output):\n",
        "        actions_map = {\n",
        "            0: \"Análise estática do código.\",\n",
        "            1: \"Executar o código.\",\n",
        "            2: \"Propor refatorações.\",\n",
        "            3: \"Aprovar o código.\",\n",
        "            4: \"Melhorar o relatório.\"\n",
        "        }\n",
        "\n",
        "        action_text = actions_map.get(action, \"\")\n",
        "        prompt = f\"{action_text}\\nCódigo:\\n{''.join([chr(c) for c in self.state['codigo'] if c > 0])}\\nErro:\\n{exec_error}\\nLinter:\\n{linter_output}\\n\"\n",
        "\n",
        "        # Usando o modelo BLOOM para gerar o feedback\n",
        "        generated = self.revisor_llm(prompt, max_new_tokens=150, num_return_sequences=1)\n",
        "        feedback = generated[0]['generated_text']\n",
        "\n",
        "        # Truncar o feedback para o tamanho máximo permitido\n",
        "        feedback = feedback[:1024]  # Truncando para 1024 caracteres\n",
        "\n",
        "        return feedback\n",
        "\n",
        "    def avaliar_codigo(self, codigo):\n",
        "        try:\n",
        "            temp_code_path = os.path.join(self.temp_dir, 'temp_code.py')\n",
        "            with open(temp_code_path, 'w') as f:\n",
        "                f.write(codigo)\n",
        "\n",
        "            result = subprocess.run(['python', temp_code_path], capture_output=True, text=True, timeout=10)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                return result.stdout, None\n",
        "            else:\n",
        "                return None, result.stderr\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, str(e)\n",
        "\n",
        "    def rodar_linter(self, codigo):\n",
        "        try:\n",
        "            temp_code_path = os.path.join(self.temp_dir, 'temp_code.py')\n",
        "            with open(temp_code_path, 'w') as f:\n",
        "                f.write(codigo)\n",
        "\n",
        "            result = subprocess.run([self.linter, temp_code_path], capture_output=True, text=True, timeout=10)\n",
        "\n",
        "            return result.stdout if result.returncode == 0 else result.stderr\n",
        "\n",
        "        except Exception as e:\n",
        "            return str(e)\n",
        "\n",
        "    def calcular_score_relatorio(self, relatorio):\n",
        "        # Simulação de cálculo de pontuação, pode ser substituído por um modelo mais complexo\n",
        "        score = len([c for c in relatorio if c.isalnum()])  # Exemplo: contar caracteres alfanuméricos\n",
        "\n",
        "        return np.array([score], dtype=np.float32)\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        if self.temp_dir:\n",
        "            shutil.rmtree(self.temp_dir)\n"
      ],
      "metadata": {
        "id": "315u38GqgRxu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando o modelo"
      ],
      "metadata": {
        "id": "Rfbep-zTvTTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar e verificar o ambiente com o arquivo CSV Walmart\n",
        "data_path = 'Walmart.csv'\n",
        "env = DataAnalysisEnv(data_path)\n",
        "check_env(env)\n",
        "\n",
        "# Vectorizando o ambiente para o treinamento com múltiplos episódios\n",
        "vec_env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# Configurando o logger para registrar os logs\n",
        "tmp_path = \"./logs/\"\n",
        "new_logger = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "\n",
        "# Inicializando e treinando o modelo\n",
        "model = PPO(\"MlpPolicy\", vec_env, verbose=1, device=device)\n",
        "model.set_logger(new_logger)\n",
        "\n",
        "model.learn(total_timesteps=30000)\n",
        "\n",
        "# Salvando o modelo treinado\n",
        "model.save(\"ppo_walmart_agents\")\n",
        "\n",
        "# Testando o ambiente após o treinamento\n",
        "obs, _ = env.reset()\n",
        "for _ in range(100):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    if done:\n",
        "        obs, _ = env.reset()\n",
        "\n",
        "# Para carregar o modelo mais tarde\n",
        "# model = PPO.load(\"ppo_data_analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nVnl-xt4m2N1",
        "outputId": "b6444ea7-8ddf-480c-dde4-22816207fcde"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Codificador ação: 2 -> Código gerado:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Mostrada a resposta.\n",
            "\n",
            "def AnaliseTemporal(df:pd.DataFrame)->str:\n",
            "\tdf = df.drop(['Unnamed: 0'], axis=1)\n",
            "\t#print(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revisor ação: 4 -> Feedback gerado:\n",
            "Melhorar o relatório.\n",
            "Código:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Mostrada a resposta.\n",
            "\n",
            "def AnaliseTemporal(df:pd.DataFrame)->str:\n",
            "\tdf = df.drop(['Unnamed: 0'], axis=1)\n",
            "\t#print(\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "    Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Mostrada a resposta.\n",
            "            ^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "Linter:\n",
            "\n",
            "\n",
            "#  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "#     Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Mostrada a resposta.\n",
            "#                                  ^^^\n",
            "\n",
            "#  File \"/tmp/tmpewk9chr7/temp_code.py\", line 3\n",
            "# Importação do Bibliotecas.\n",
            "import os\n",
            "\n",
            "# Cria uma pasta p\n",
            "Recompensa Codificador: -1.0, Recompensa Revisor: 0.006666666666666667, Recompensa Combinada: -0.49666666666666665\n",
            "Codificador ação: 1 -> Código gerado:\n",
            "Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. A seguir usa a base, nome do produto, quantidade minima e peso para analise exploratória,\n",
            "print a tabela contendo as informações das vendas,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revisor ação: 1 -> Feedback gerado:\n",
            "Executar o código.\n",
            "Código:\n",
            "Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. A seguir usa a base, nome do produto, quantidade minima e peso para analise exploratória,\n",
            "print a tabela contendo as informações das vendas,\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "    Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. A seguir usa a base, nome do produto, quantidade minima e peso para analise exploratória,\n",
            "            ^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "Linter:\n",
            "\n",
            "    File \"/tmp/tmpewk9chr7/python_test.py\", line 1\n",
            "        Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. A seguir utiliza a base, nome do produto, quantidade minimo e peso para realizar estética\n",
            "Recompensa Codificador: -1.0, Recompensa Revisor: 0.006666666666666667, Recompensa Combinada: -0.49666666666666665\n",
            "Codificador ação: 2 -> Código gerado:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Um excel vantuável a partir da vendas dos produtos da Amazon para se fazer um gráfico de dispersões.\\n')\n",
            "\n",
            "\n",
            "if(menu.upper()=='Abrir\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revisor ação: 4 -> Feedback gerado:\n",
            "Melhorar o relatório.\n",
            "Código:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Um excel vantuável a partir da vendas dos produtos da Amazon para se fazer um gráfico de dispersões.\\n')\n",
            "\n",
            "\n",
            "if(menu.upper()=='Abriras,\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "    Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Um excel vantuável a partir da vendas dos produtos da Amazon para se fazer um gráfico de dispersões.\\n')\n",
            "            ^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "Linter:\n",
            "\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "   \n",
            "  'print(\"Hola Mundo!\")'\n",
            "\n",
            "Linter:\n",
            "\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 9\n",
            "   print(\"Hola Mundo!\")\n",
            "\n",
            "Linter:\n",
            "\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 5\n",
            "                   Escreva uma função Python para Visualizar os resultados. us\n",
            "Recompensa Codificador: -1.0, Recompensa Revisor: 0.006666666666666667, Recompensa Combinada: -0.49666666666666665\n",
            "Codificador ação: 2 -> Código gerado:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "def analise_Temporal(Data): \n",
            "    #Se a função for chamada, a função retorna um dicionário, com as variáveis\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revisor ação: 1 -> Feedback gerado:\n",
            "Executar o código.\n",
            "Código:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "def analise_Temporal(Data): \n",
            "    #Se a função for chamada, a função retorna um dicionário, com as variáveis\n",
            "    r()=='Abriras,\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 4\n",
            "    \"\"\"\n",
            "    ^\n",
            "SyntaxError: unterminated triple-quoted string literal (detected at line 8)\n",
            "\n",
            "Linter:\n",
            "\n",
            "  [21:19:27]   SyntaxError: non-default argument = None\n",
            "  [21:19:27]   File \"temp_code.py\", line 3, in teste\n",
            "\n",
            "  TypeError\n",
            "    raise ValueError ('int expected') from None\n",
            "\n",
            "  File \"/tmp/12e01d077/temp_code.py\", line 21, in teste\n",
            "    raise TypeError ('String expected') from None\n",
            "\n",
            "  Exception:\n",
            "\n",
            "  Incorrect data type: NoneType\n",
            "  \"\"\"   \n",
            "    #print(\"Teste\")\n",
            "\n",
            "#Entrada do texto: Realize estes as funções\n",
            "#Saída do texto: Realize\n",
            "Recompensa Codificador: -1.0, Recompensa Revisor: 0.006666666666666667, Recompensa Combinada: -0.49666666666666665\n",
            "Codificador ação: 3 -> Código gerado:\n",
            "Escreva uma função Python para Interpretar a análise. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "\n",
            "def InterpolaDadosDados():\n",
            "    \n",
            "    #Definição de uma lista para armazenar os dados utilizados na analise\n",
            "    dataframe = []\n",
            "    \n",
            "    #\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revisor ação: 2 -> Feedback gerado:\n",
            "Propor refatorações.\n",
            "Código:\n",
            "Escreva uma função Python para Interpretar a análise. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "\n",
            "def InterpolaDadosDados():\n",
            "    \n",
            "    #Definição de uma lista para armazenar os dados utilizados na analise\n",
            "    dataframe = []\n",
            "    \n",
            "    #\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "    Escreva uma função Python para Interpretar a análise. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "            ^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "Linter:\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "import os\n",
            "\n",
            "\n",
            "def InterpolaDadosDados():\n",
            "    \n",
            "    #Definição de uma lista para armazenar os dados utilizados na analise\n",
            "    dataframe = []\n",
            "    \n",
            "    #\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "    Escreva uma função Python para Interpretar a análise. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "            ^^^\n",
            "S\n",
            "Recompensa Codificador: -1.0, Recompensa Revisor: 0.006666666666666667, Recompensa Combinada: -0.49666666666666665\n",
            "Codificador ação: 1 -> Código gerado:\n",
            "Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "\n",
            "  Observe que, com base em vendas por tipo de dúvidas, a quantidade de registros de vendas é binário \n",
            "\n",
            "\n",
            "def main():\n",
            "  # Selecionar a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revisor ação: 1 -> Feedback gerado:\n",
            "Executar o código.\n",
            "Código:\n",
            "Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "\n",
            "  Observe que, com base em vendas por tipo de dúvidas, a quantidade de registros de vendas é binário \n",
            "\n",
            "\n",
            "def main():\n",
            "  # Selecionar a \n",
            "    #\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "    Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal.\n",
            "            ^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "Linter:\n",
            "\n",
            "  Una instrução dentro de uma função o Python é muito intuitiva. Para ler algo do python segue a página\n",
            "    https://docs.python.org/3.4/library/functions.html#python-functions-functions-filter\n",
            "\n",
            "  O python é um banco de dados onde cada função deve estar sendo colocado em ordem alfabetica ou ordem numérica. Pula pela\n",
            "    documentação abaixo: https://docs.python.org/3/library/functions.html#python-functions\n",
            "Recompensa Codificador: -1.0, Recompensa Revisor: 0.006666666666666667, Recompensa Combinada: -0.49666666666666665\n",
            "Codificador ação: 2 -> Código gerado:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Para resolver todo a situação de uma distribuição, ele foi um relatório composto da venda pelo número de vendas de vendas das 3 prestaç\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revisor ação: 1 -> Feedback gerado:\n",
            "Executar o código.\n",
            "Código:\n",
            "Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Para resolver todo a situação de uma distribuição, ele foi um relatório composto da venda pelo número de vendas de vendas das 3 prestaç\n",
            "Erro:\n",
            "  File \"/tmp/tmpewk9chr7/temp_code.py\", line 1\n",
            "    Escreva uma função Python para Visualizar os resultados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. Para resolver todo a situação de uma distribuição, ele foi um relatório composto da venda pelo número de vendas de vendas das 3 prestaç\n",
            "            ^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "Linter:\n",
            "\n",
            "    import datetime\n",
            "from datetime import datetime as dt\n",
            "\n",
            "\n",
            "# Estrutura de repetição\n",
            "while True:\n",
            "    # Recebe a data de referência ao projeto\n",
            "    data = input(\"Data: \")\n",
            "    data_format = data.split(\"-\")\n",
            "    # Formata a data em texto com o formato: DD-MM-YYYY\n",
            "    d\n",
            "Recompensa Codificador: -1.0, Recompensa Revisor: 0.006666666666666667, Recompensa Combinada: -0.49666666666666665\n",
            "Codificador ação: 1 -> Código gerado:\n",
            "Escreva uma função Python para Analisar os dados. usando a coluna de Date e Weekly_Sales do dataset Walmart.csv de vendas da Walmart para realizar uma análise temporal. O campo de tempo do dataset ficara em 0 e 1\n",
            "\n",
            "import pandas as pd\n",
            "import pymysql\n",
            "from pymysql.cursors import Cursor\n",
            "import matplotlib.pyplot as\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e02de9799836>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Walmart.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataAnalysisEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheck_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Vectorizando o ambiente para o treinamento com múltiplos episódios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py\u001b[0m in \u001b[0;36mcheck_env\u001b[0;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# The check doesn't support nested observations/dict actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;31m# A warning about it has already been emitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0m_check_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py\u001b[0m in \u001b[0;36m_check_nan\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/vec_check_nan.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"step_wait\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-12-237dd3157dad>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Revisor gera feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_action_revisor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_revisor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinter_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relatorio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeedback\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Usa ord() para valores Unicode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-237dd3157dad>\u001b[0m in \u001b[0;36mexecute_action_revisor\u001b[0;34m(self, action, exec_error, linter_output)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Usando o modelo BLOOM para gerar o feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrevisor_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1255\u001b[0m             )\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m    668\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    534\u001b[0m                 )\n\u001b[1;32m    535\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    537\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# compute self-attention: V x Softmax(QK^T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k84-oK33s8b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"Salesforce/codegen-350M-mono\")\n",
        "prompt = \"Write a Python function to calculate the factorial of a number\"\n",
        "result = generator(prompt, max_length=100)\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "OfNGUhiPgSKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26e3426-8171-499f-bd24-271ed54253e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a Python function to calculate the factorial of a number for integer inputs\n",
            "\n",
            "\n",
            "def factorial(x):\n",
            "    try:\n",
            "        x=int(x)\n",
            "        if (x>=1):\n",
            "            result=1\n",
            "            for i in range(1,x+1): #using while loop to find out the factorial of 1 to n\n",
            "                result=result*i\n",
            "            return (result) #returning the factorial\n",
            "\n",
            "    except ValueError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4U8QgqQccAPT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}